{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime, time, json\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_corpus = np.load(\"/Users/zhang/MscProject_tweak2vec/corpus/quora_corpus_int5.npy\")\n",
    "labels = np.load(\"/Users/zhang/MscProject_tweak2vec/corpus/quora_labels.npy\")\n",
    "\n",
    "w2v_google_50d = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/w2v_google_50d.npy\")\n",
    "w2v_pivots100_50d = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/w2v_quora_50d_5m.npy\")\n",
    "\n",
    "#w2v_retrain = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/w2v_retrain5.npy\")\n",
    "\n",
    "w2v_concat = concat_vec = np.concatenate([w2v_google_50d, w2v_quora_50d_5m], axis=1)\n",
    "w2v_avg = (w2v_google_50d + w2v_quora_50d)/2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30300, 50)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "w2v_concat = pca.fit_transform(w2v_concat)\n",
    "w2v_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = w2v_concat[:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate question1 and question2\n",
    "question1 = []\n",
    "question2 = []\n",
    "for n in range(int(len(quora_corpus)/2)):\n",
    "    question1.append(quora_corpus[2*n])\n",
    "    question2.append(quora_corpus[2*n+1])\n",
    "    \n",
    "q1_data = pad_sequences(question1, maxlen=25)\n",
    "q2_data = pad_sequences(question2, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:190, average length:8.62675648734686\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "l_avg = []\n",
    "for i in range(len(quora_corpus)):\n",
    "    if len(quora_corpus[i]) > l:\n",
    "        l = len(quora_corpus[i])\n",
    "    l_avg.append(len(quora_corpus[i]))\n",
    "print('max length:{0}, average length:{1}'.format(l,np.mean(np.array(l_avg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameter setup\n",
    "max_sentence_len = 25\n",
    "embed_dim = 50\n",
    "dropout_rate = 0.1\n",
    "vocab_size = len(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split cross validation set and test set\n",
    "questions = np.stack((q1_data, q2_data), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions, labels, test_size=0.1, random_state=2018)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question1 = Input(shape=(max_sentence_len,))\n",
    "question2 = Input(shape=(max_sentence_len,))\n",
    "\n",
    "\n",
    "\n",
    "q1 = Embedding(  input_dim=vocab_size, \n",
    "                 output_dim=embed_dim, \n",
    "                 weights=[word_embedding], \n",
    "                 input_length=max_sentence_len, \n",
    "                 trainable=False)(question1)\n",
    "q1 = TimeDistributed(Dense(embed_dim, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embed_dim, ))(q1)\n",
    "\n",
    "q2 = Embedding(  input_dim=vocab_size, \n",
    "                 output_dim=embed_dim, \n",
    "                 weights=[word_embedding], \n",
    "                 input_length=max_sentence_len, \n",
    "                 trainable=False)(question2)\n",
    "q2 = TimeDistributed(Dense(embed_dim, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embed_dim, ))(q2)\n",
    "\n",
    "merged = concatenate([q1,q2])\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(dropout_rate)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(dropout_rate)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(dropout_rate)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(dropout_rate)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "val_split = 0.1\n",
    "batch_size = 32\n",
    "MODEL_WEIGHTS_FILE = '/Users/zhang/MscProject_tweak2vec/Max_BOE_weights/concat_50d_5m_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-07-06 00:19:31.724102\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      " - 79s - loss: 0.5457 - acc: 0.7199 - val_loss: 0.4969 - val_acc: 0.7518\n",
      "Epoch 2/50\n",
      " - 75s - loss: 0.5050 - acc: 0.7481 - val_loss: 0.4789 - val_acc: 0.7665\n",
      "Epoch 3/50\n",
      " - 75s - loss: 0.4909 - acc: 0.7562 - val_loss: 0.4714 - val_acc: 0.7678\n",
      "Epoch 4/50\n",
      " - 75s - loss: 0.4811 - acc: 0.7622 - val_loss: 0.4639 - val_acc: 0.7751\n",
      "Epoch 5/50\n",
      " - 75s - loss: 0.4738 - acc: 0.7666 - val_loss: 0.4589 - val_acc: 0.7750\n",
      "Epoch 6/50\n",
      " - 74s - loss: 0.4684 - acc: 0.7700 - val_loss: 0.4509 - val_acc: 0.7813\n",
      "Epoch 7/50\n",
      " - 75s - loss: 0.4635 - acc: 0.7738 - val_loss: 0.4559 - val_acc: 0.7775\n",
      "Epoch 8/50\n",
      " - 75s - loss: 0.4592 - acc: 0.7771 - val_loss: 0.4496 - val_acc: 0.7842\n",
      "Epoch 9/50\n",
      " - 75s - loss: 0.4554 - acc: 0.7788 - val_loss: 0.4461 - val_acc: 0.7840\n",
      "Epoch 10/50\n",
      " - 75s - loss: 0.4529 - acc: 0.7800 - val_loss: 0.4430 - val_acc: 0.7826\n",
      "Epoch 11/50\n",
      " - 75s - loss: 0.4496 - acc: 0.7818 - val_loss: 0.4450 - val_acc: 0.7812\n",
      "Epoch 12/50\n",
      " - 75s - loss: 0.4473 - acc: 0.7836 - val_loss: 0.4422 - val_acc: 0.7862\n",
      "Epoch 13/50\n",
      " - 75s - loss: 0.4449 - acc: 0.7849 - val_loss: 0.4415 - val_acc: 0.7861\n",
      "Epoch 14/50\n",
      " - 75s - loss: 0.4423 - acc: 0.7874 - val_loss: 0.4332 - val_acc: 0.7909\n",
      "Epoch 15/50\n",
      " - 75s - loss: 0.4401 - acc: 0.7886 - val_loss: 0.4373 - val_acc: 0.7869\n",
      "Epoch 16/50\n",
      " - 75s - loss: 0.4388 - acc: 0.7890 - val_loss: 0.4344 - val_acc: 0.7898\n",
      "Epoch 17/50\n",
      " - 75s - loss: 0.4358 - acc: 0.7905 - val_loss: 0.4316 - val_acc: 0.7922\n",
      "Epoch 18/50\n",
      " - 75s - loss: 0.4344 - acc: 0.7920 - val_loss: 0.4312 - val_acc: 0.7923\n",
      "Epoch 19/50\n",
      " - 75s - loss: 0.4339 - acc: 0.7924 - val_loss: 0.4319 - val_acc: 0.7925\n",
      "Epoch 20/50\n",
      " - 75s - loss: 0.4312 - acc: 0.7932 - val_loss: 0.4332 - val_acc: 0.7934\n",
      "Epoch 21/50\n",
      " - 75s - loss: 0.4296 - acc: 0.7950 - val_loss: 0.4268 - val_acc: 0.7938\n",
      "Epoch 22/50\n",
      " - 75s - loss: 0.4284 - acc: 0.7955 - val_loss: 0.4316 - val_acc: 0.7932\n",
      "Epoch 23/50\n",
      " - 75s - loss: 0.4281 - acc: 0.7955 - val_loss: 0.4289 - val_acc: 0.7939\n",
      "Epoch 24/50\n",
      " - 75s - loss: 0.4262 - acc: 0.7962 - val_loss: 0.4282 - val_acc: 0.7959\n",
      "Epoch 25/50\n",
      " - 75s - loss: 0.4259 - acc: 0.7957 - val_loss: 0.4285 - val_acc: 0.7941\n",
      "Epoch 26/50\n",
      " - 75s - loss: 0.4231 - acc: 0.7990 - val_loss: 0.4307 - val_acc: 0.7946\n",
      "Epoch 27/50\n",
      " - 75s - loss: 0.4229 - acc: 0.7987 - val_loss: 0.4267 - val_acc: 0.7976\n",
      "Epoch 28/50\n",
      " - 75s - loss: 0.4213 - acc: 0.7995 - val_loss: 0.4299 - val_acc: 0.7931\n",
      "Epoch 29/50\n",
      " - 75s - loss: 0.4216 - acc: 0.7993 - val_loss: 0.4290 - val_acc: 0.7942\n",
      "Epoch 30/50\n",
      " - 75s - loss: 0.4200 - acc: 0.8004 - val_loss: 0.4247 - val_acc: 0.7960\n",
      "Epoch 31/50\n",
      " - 75s - loss: 0.4185 - acc: 0.8009 - val_loss: 0.4256 - val_acc: 0.7960\n",
      "Epoch 32/50\n",
      " - 75s - loss: 0.4176 - acc: 0.8008 - val_loss: 0.4234 - val_acc: 0.7959\n",
      "Epoch 33/50\n",
      " - 74s - loss: 0.4162 - acc: 0.8021 - val_loss: 0.4237 - val_acc: 0.7985\n",
      "Epoch 34/50\n",
      " - 75s - loss: 0.4156 - acc: 0.8027 - val_loss: 0.4216 - val_acc: 0.7981\n",
      "Epoch 35/50\n",
      " - 75s - loss: 0.4156 - acc: 0.8026 - val_loss: 0.4212 - val_acc: 0.7972\n",
      "Epoch 36/50\n",
      " - 75s - loss: 0.4156 - acc: 0.8029 - val_loss: 0.4249 - val_acc: 0.7968\n",
      "Epoch 37/50\n",
      " - 75s - loss: 0.4152 - acc: 0.8030 - val_loss: 0.4222 - val_acc: 0.7982\n",
      "Epoch 38/50\n",
      " - 75s - loss: 0.4138 - acc: 0.8037 - val_loss: 0.4236 - val_acc: 0.7976\n",
      "Epoch 39/50\n",
      " - 75s - loss: 0.4122 - acc: 0.8043 - val_loss: 0.4218 - val_acc: 0.8002\n",
      "Epoch 40/50\n",
      " - 75s - loss: 0.4116 - acc: 0.8057 - val_loss: 0.4234 - val_acc: 0.7996\n",
      "Epoch 41/50\n",
      " - 75s - loss: 0.4119 - acc: 0.8051 - val_loss: 0.4215 - val_acc: 0.7991\n",
      "Epoch 42/50\n",
      " - 75s - loss: 0.4104 - acc: 0.8056 - val_loss: 0.4233 - val_acc: 0.7992\n",
      "Epoch 43/50\n",
      " - 75s - loss: 0.4107 - acc: 0.8061 - val_loss: 0.4219 - val_acc: 0.8004\n",
      "Epoch 44/50\n",
      " - 75s - loss: 0.4096 - acc: 0.8066 - val_loss: 0.4189 - val_acc: 0.8010\n",
      "Epoch 45/50\n",
      " - 75s - loss: 0.4096 - acc: 0.8062 - val_loss: 0.4213 - val_acc: 0.8003\n",
      "Epoch 46/50\n",
      " - 75s - loss: 0.4095 - acc: 0.8067 - val_loss: 0.4221 - val_acc: 0.7992\n",
      "Epoch 47/50\n",
      " - 75s - loss: 0.4087 - acc: 0.8073 - val_loss: 0.4190 - val_acc: 0.8002\n",
      "Epoch 48/50\n",
      " - 75s - loss: 0.4080 - acc: 0.8080 - val_loss: 0.4217 - val_acc: 0.7977\n",
      "Epoch 49/50\n",
      " - 75s - loss: 0.4076 - acc: 0.8070 - val_loss: 0.4206 - val_acc: 0.8003\n",
      "Epoch 50/50\n",
      " - 75s - loss: 0.4072 - acc: 0.8077 - val_loss: 0.4202 - val_acc: 0.7993\n",
      "Training ended at 2018-07-06 01:22:12.007389\n",
      "Minutes elapsed: 62.671377\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=n_epoch,\n",
    "                    validation_split=val_split,\n",
    "                    verbose=2,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4726, accuracy = 0.8038\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 25, 50)       1515000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 25, 50)       1515000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 25, 50)       2550        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 25, 50)       2550        embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100)          0           lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 200)          20200       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 200)          800         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 200)          40200       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 200)          800         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 200)          40200       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 200)          800         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 200)          40200       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 200)          0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200)          800         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            201         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,179,301\n",
      "Trainable params: 147,701\n",
      "Non-trainable params: 3,031,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
