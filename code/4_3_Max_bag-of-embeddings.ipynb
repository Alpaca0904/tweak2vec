{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhang/anaconda/envs/mlp/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime, time, json\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, History\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_corpus = np.load(\"/Users/zhang/MscProject_tweak2vec/corpus/quora_corpus_int5.npy\")\n",
    "labels = np.load(\"/Users/zhang/MscProject_tweak2vec/corpus/quora_labels.npy\")\n",
    "\n",
    "w2v_embedding = {}\n",
    "w2v_embedding['pivots300_7m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_7m.npy\")\n",
    "w2v_embedding['pivots300_6m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_6m.npy\")\n",
    "w2v_embedding['pivots300_5m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_5m.npy\")\n",
    "w2v_embedding['pivots300_4m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_4m.npy\")\n",
    "w2v_embedding['pivots300_3m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_3m.npy\")\n",
    "w2v_embedding['pivots300_2m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_2m.npy\")\n",
    "w2v_embedding['pivots300_1m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_1m.npy\")\n",
    "w2v_embedding['pivots300_05m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_05m.npy\")\n",
    "w2v_embedding['pivots300_01m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_01m.npy\")\n",
    "w2v_embedding['pivots300_005m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_005m.npy\")\n",
    "w2v_embedding['pivots300_001m'] = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots300_001m.npy\")\n",
    "\n",
    "#w2v_concat = concat_vec = np.concatenate([w2v_google_50d, w2v_pivots100_50d], axis=1)\n",
    "#w2v_avg = (w2v_google_50d + w2v_quora_50d)/2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "w2v_concat = pca.fit_transform(w2v_concat)\n",
    "w2v_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate question1 and question2\n",
    "question1 = []\n",
    "question2 = []\n",
    "for n in range(int(len(quora_corpus)/2)):\n",
    "    question1.append(quora_corpus[2*n])\n",
    "    question2.append(quora_corpus[2*n+1])\n",
    "    \n",
    "q1_data = pad_sequences(question1, maxlen=25)\n",
    "q2_data = pad_sequences(question2, maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:190, average length:8.62675648734686\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "l_avg = []\n",
    "for i in range(len(quora_corpus)):\n",
    "    if len(quora_corpus[i]) > l:\n",
    "        l = len(quora_corpus[i])\n",
    "    l_avg.append(len(quora_corpus[i]))\n",
    "print('max length:{0}, average length:{1}'.format(l,np.mean(np.array(l_avg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter setup\n",
    "max_sentence_len = 25\n",
    "embed_dim = 50\n",
    "dropout_rate = 0.1\n",
    "vocab_size = len(w2v_embedding['pivots300_7m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split cross validation set and test set\n",
    "questions = np.stack((q1_data, q2_data), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions, labels, test_size=0.1, random_state=2018)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Max_BoE(word_embedding):\n",
    "\n",
    "    question1 = Input(shape=(max_sentence_len,))\n",
    "    question2 = Input(shape=(max_sentence_len,))\n",
    "\n",
    "\n",
    "\n",
    "    q1 = Embedding(  input_dim=vocab_size, \n",
    "                     output_dim=embed_dim, \n",
    "                     weights=[word_embedding], \n",
    "                     input_length=max_sentence_len, \n",
    "                     trainable=False)(question1)\n",
    "    q1 = TimeDistributed(Dense(embed_dim, activation='relu'))(q1)\n",
    "    q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embed_dim, ))(q1)\n",
    "\n",
    "    q2 = Embedding(  input_dim=vocab_size, \n",
    "                     output_dim=embed_dim, \n",
    "                     weights=[word_embedding], \n",
    "                     input_length=max_sentence_len, \n",
    "                     trainable=False)(question2)\n",
    "    q2 = TimeDistributed(Dense(embed_dim, activation='relu'))(q2)\n",
    "    q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embed_dim, ))(q2)\n",
    "\n",
    "    merged = concatenate([q1,q2])\n",
    "    merged = Dense(200, activation='relu')(merged)\n",
    "    merged = Dropout(dropout_rate)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dense(200, activation='relu')(merged)\n",
    "    merged = Dropout(dropout_rate)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dense(200, activation='relu')(merged)\n",
    "    merged = Dropout(dropout_rate)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dense(200, activation='relu')(merged)\n",
    "    merged = Dropout(dropout_rate)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "val_split = 0.1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-07-15 14:00:01.172311\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 113s 344us/step - loss: 0.5560 - acc: 0.7162 - val_loss: 0.5088 - val_acc: 0.7482\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 111s 339us/step - loss: 0.5129 - acc: 0.7442 - val_loss: 0.4905 - val_acc: 0.7579\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 98s 301us/step - loss: 0.4976 - acc: 0.7531 - val_loss: 0.4854 - val_acc: 0.7605\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 112s 343us/step - loss: 0.4876 - acc: 0.7590 - val_loss: 0.4763 - val_acc: 0.7660\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 100s 306us/step - loss: 0.4812 - acc: 0.7625 - val_loss: 0.4717 - val_acc: 0.7679\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 97s 297us/step - loss: 0.4764 - acc: 0.7658 - val_loss: 0.4663 - val_acc: 0.7731\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 109s 332us/step - loss: 0.4709 - acc: 0.7686 - val_loss: 0.4609 - val_acc: 0.7745\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 99s 302us/step - loss: 0.4673 - acc: 0.7705 - val_loss: 0.4652 - val_acc: 0.7703\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 95s 289us/step - loss: 0.4637 - acc: 0.7734 - val_loss: 0.4573 - val_acc: 0.7783\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 87s 267us/step - loss: 0.4604 - acc: 0.7746 - val_loss: 0.4543 - val_acc: 0.7802\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 84s 257us/step - loss: 0.4581 - acc: 0.7765 - val_loss: 0.4556 - val_acc: 0.7794\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 85s 258us/step - loss: 0.4547 - acc: 0.7788 - val_loss: 0.4541 - val_acc: 0.7799\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4538 - acc: 0.7789 - val_loss: 0.4543 - val_acc: 0.7830\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 84s 257us/step - loss: 0.4515 - acc: 0.7805 - val_loss: 0.4570 - val_acc: 0.7805\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4505 - acc: 0.7815 - val_loss: 0.4521 - val_acc: 0.7814\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 85s 260us/step - loss: 0.4479 - acc: 0.7819 - val_loss: 0.4509 - val_acc: 0.7829\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 83s 252us/step - loss: 0.4472 - acc: 0.7835 - val_loss: 0.4479 - val_acc: 0.7841\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 85s 258us/step - loss: 0.4445 - acc: 0.7847 - val_loss: 0.4443 - val_acc: 0.7862\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 85s 259us/step - loss: 0.4436 - acc: 0.7850 - val_loss: 0.4454 - val_acc: 0.7863\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 85s 259us/step - loss: 0.4425 - acc: 0.7853 - val_loss: 0.4494 - val_acc: 0.7840\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4410 - acc: 0.7864 - val_loss: 0.4517 - val_acc: 0.7779\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4396 - acc: 0.7875 - val_loss: 0.4469 - val_acc: 0.7865\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4385 - acc: 0.7881 - val_loss: 0.4442 - val_acc: 0.7857\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 102s 312us/step - loss: 0.4379 - acc: 0.7884 - val_loss: 0.4455 - val_acc: 0.7848\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4369 - acc: 0.7892 - val_loss: 0.4451 - val_acc: 0.7856\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 104s 318us/step - loss: 0.4364 - acc: 0.7900 - val_loss: 0.4428 - val_acc: 0.7874\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 101s 307us/step - loss: 0.4352 - acc: 0.7901 - val_loss: 0.4409 - val_acc: 0.7877\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 99s 301us/step - loss: 0.4345 - acc: 0.7911 - val_loss: 0.4418 - val_acc: 0.7868\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 100s 306us/step - loss: 0.4326 - acc: 0.7918 - val_loss: 0.4404 - val_acc: 0.7890\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 100s 307us/step - loss: 0.4322 - acc: 0.7921 - val_loss: 0.4398 - val_acc: 0.7879\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 97s 296us/step - loss: 0.4321 - acc: 0.7922 - val_loss: 0.4457 - val_acc: 0.7848\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 100s 305us/step - loss: 0.4309 - acc: 0.7923 - val_loss: 0.4418 - val_acc: 0.7870\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 92s 282us/step - loss: 0.4296 - acc: 0.7928 - val_loss: 0.4406 - val_acc: 0.7871\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 98s 299us/step - loss: 0.4285 - acc: 0.7934 - val_loss: 0.4389 - val_acc: 0.7882\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 100s 304us/step - loss: 0.4287 - acc: 0.7939 - val_loss: 0.4399 - val_acc: 0.7877\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 100s 305us/step - loss: 0.4287 - acc: 0.7938 - val_loss: 0.4402 - val_acc: 0.7874\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 97s 297us/step - loss: 0.4274 - acc: 0.7952 - val_loss: 0.4392 - val_acc: 0.7876\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 104s 316us/step - loss: 0.4254 - acc: 0.7960 - val_loss: 0.4411 - val_acc: 0.7888\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 107s 327us/step - loss: 0.4261 - acc: 0.7960 - val_loss: 0.4437 - val_acc: 0.7855\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 115s 350us/step - loss: 0.4248 - acc: 0.7966 - val_loss: 0.4393 - val_acc: 0.7881\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 92s 282us/step - loss: 0.4246 - acc: 0.7965 - val_loss: 0.4417 - val_acc: 0.7882\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 106s 324us/step - loss: 0.4244 - acc: 0.7968 - val_loss: 0.4390 - val_acc: 0.7883\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 98s 300us/step - loss: 0.4231 - acc: 0.7973 - val_loss: 0.4368 - val_acc: 0.7899\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 99s 302us/step - loss: 0.4230 - acc: 0.7976 - val_loss: 0.4387 - val_acc: 0.7900\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 94s 286us/step - loss: 0.4228 - acc: 0.7976 - val_loss: 0.4390 - val_acc: 0.7912\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 90s 275us/step - loss: 0.4226 - acc: 0.7977 - val_loss: 0.4387 - val_acc: 0.7904\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 95s 292us/step - loss: 0.4230 - acc: 0.7975 - val_loss: 0.4399 - val_acc: 0.7910\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 89s 273us/step - loss: 0.4224 - acc: 0.7976 - val_loss: 0.4388 - val_acc: 0.7914\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 92s 282us/step - loss: 0.4220 - acc: 0.7982 - val_loss: 0.4372 - val_acc: 0.7906\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 91s 279us/step - loss: 0.4213 - acc: 0.7991 - val_loss: 0.4395 - val_acc: 0.7908\n",
      "Training ended at 2018-07-15 15:19:32.974756\n",
      "Minutes elapsed: 79.530015\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "current_embed = np.load(\"/Users/zhang/MscProject_tweak2vec/word2vecModel/quora/tokens/w2v_pivots100_07m.npy\")\n",
    "model = Max_BoE(current_embed)\n",
    "MODEL_WEIGHTS_FILE = '/Users/zhang/MscProject_tweak2vec/Max_BOE_weights/pivots100_07m.h5'\n",
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "model_history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=n_epoch,\n",
    "                    validation_split=val_split,\n",
    "                    verbose=1,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks)\n",
    "data = model_history.history\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))\n",
    "print(\"-------------------------------------------------------------------------\") \n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('pivots100_07m_data.txt','w')\n",
    "f.write(str(save_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current embedding:  pivots300_7m\n",
      "Starting training at 2018-07-13 19:03:38.603639\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5508 - acc: 0.7188 - val_loss: 0.4981 - val_acc: 0.7541\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 67s 205us/step - loss: 0.5021 - acc: 0.7511 - val_loss: 0.4774 - val_acc: 0.7633\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 62s 188us/step - loss: 0.4833 - acc: 0.7620 - val_loss: 0.4627 - val_acc: 0.7726\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 62s 188us/step - loss: 0.4736 - acc: 0.7679 - val_loss: 0.4528 - val_acc: 0.7794\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 62s 188us/step - loss: 0.4664 - acc: 0.7727 - val_loss: 0.4520 - val_acc: 0.7802\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 61s 188us/step - loss: 0.4599 - acc: 0.7761 - val_loss: 0.4466 - val_acc: 0.7849\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4564 - acc: 0.7792 - val_loss: 0.4461 - val_acc: 0.7851\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 62s 188us/step - loss: 0.4519 - acc: 0.7808 - val_loss: 0.4401 - val_acc: 0.7896\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 62s 188us/step - loss: 0.4481 - acc: 0.7828 - val_loss: 0.4411 - val_acc: 0.7889\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4451 - acc: 0.7848 - val_loss: 0.4371 - val_acc: 0.7896\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4426 - acc: 0.7870 - val_loss: 0.4360 - val_acc: 0.7902\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4391 - acc: 0.7893 - val_loss: 0.4353 - val_acc: 0.7914\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4373 - acc: 0.7903 - val_loss: 0.4314 - val_acc: 0.7924\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4353 - acc: 0.7904 - val_loss: 0.4314 - val_acc: 0.7918\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4329 - acc: 0.7925 - val_loss: 0.4308 - val_acc: 0.7939\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4320 - acc: 0.7938 - val_loss: 0.4281 - val_acc: 0.7936\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 61s 188us/step - loss: 0.4300 - acc: 0.7944 - val_loss: 0.4269 - val_acc: 0.7972\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4275 - acc: 0.7957 - val_loss: 0.4298 - val_acc: 0.7947\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4266 - acc: 0.7958 - val_loss: 0.4285 - val_acc: 0.7972\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4254 - acc: 0.7965 - val_loss: 0.4258 - val_acc: 0.7974\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4250 - acc: 0.7974 - val_loss: 0.4225 - val_acc: 0.7998\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 67s 206us/step - loss: 0.4229 - acc: 0.7980 - val_loss: 0.4235 - val_acc: 0.7985\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 68s 207us/step - loss: 0.4213 - acc: 0.7992 - val_loss: 0.4223 - val_acc: 0.7988\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 65s 197us/step - loss: 0.4208 - acc: 0.7995 - val_loss: 0.4217 - val_acc: 0.7986\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4197 - acc: 0.8003 - val_loss: 0.4227 - val_acc: 0.7982\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 65s 198us/step - loss: 0.4196 - acc: 0.8009 - val_loss: 0.4229 - val_acc: 0.7995\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 64s 196us/step - loss: 0.4183 - acc: 0.8013 - val_loss: 0.4201 - val_acc: 0.7997\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4168 - acc: 0.8023 - val_loss: 0.4224 - val_acc: 0.8000\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4154 - acc: 0.8033 - val_loss: 0.4197 - val_acc: 0.8014\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 63s 192us/step - loss: 0.4151 - acc: 0.8034 - val_loss: 0.4234 - val_acc: 0.8007\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 63s 192us/step - loss: 0.4154 - acc: 0.8030 - val_loss: 0.4213 - val_acc: 0.8012\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4129 - acc: 0.8045 - val_loss: 0.4178 - val_acc: 0.8017\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4130 - acc: 0.8057 - val_loss: 0.4193 - val_acc: 0.8009\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 65s 198us/step - loss: 0.4122 - acc: 0.8048 - val_loss: 0.4180 - val_acc: 0.8023\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4111 - acc: 0.8052 - val_loss: 0.4181 - val_acc: 0.8025\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 65s 199us/step - loss: 0.4105 - acc: 0.8065 - val_loss: 0.4176 - val_acc: 0.8031\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4097 - acc: 0.8060 - val_loss: 0.4168 - val_acc: 0.8028\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 66s 201us/step - loss: 0.4098 - acc: 0.8063 - val_loss: 0.4195 - val_acc: 0.8026\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 68s 207us/step - loss: 0.4095 - acc: 0.8066 - val_loss: 0.4184 - val_acc: 0.8045\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4090 - acc: 0.8068 - val_loss: 0.4204 - val_acc: 0.8031\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 79s 240us/step - loss: 0.4085 - acc: 0.8072 - val_loss: 0.4200 - val_acc: 0.8019\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 80s 245us/step - loss: 0.4090 - acc: 0.8070 - val_loss: 0.4166 - val_acc: 0.8048\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 85s 260us/step - loss: 0.4084 - acc: 0.8075 - val_loss: 0.4176 - val_acc: 0.8018\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4072 - acc: 0.8079 - val_loss: 0.4200 - val_acc: 0.8011\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 76s 231us/step - loss: 0.4071 - acc: 0.8083 - val_loss: 0.4183 - val_acc: 0.8034\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4058 - acc: 0.8087 - val_loss: 0.4179 - val_acc: 0.8050\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 67s 204us/step - loss: 0.4061 - acc: 0.8090 - val_loss: 0.4175 - val_acc: 0.8026\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 63s 192us/step - loss: 0.4051 - acc: 0.8092 - val_loss: 0.4206 - val_acc: 0.8009\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4057 - acc: 0.8091 - val_loss: 0.4201 - val_acc: 0.8019\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 62s 189us/step - loss: 0.4051 - acc: 0.8098 - val_loss: 0.4181 - val_acc: 0.8021\n",
      "Training ended at 2018-07-13 19:58:04.929735\n",
      "Minutes elapsed: 54.438754\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_6m\n",
      "Starting training at 2018-07-13 19:58:07.018563\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.5465 - acc: 0.7227 - val_loss: 0.4978 - val_acc: 0.7531\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 67s 204us/step - loss: 0.5033 - acc: 0.7497 - val_loss: 0.4768 - val_acc: 0.7665\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4856 - acc: 0.7602 - val_loss: 0.4625 - val_acc: 0.7737\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4741 - acc: 0.7675 - val_loss: 0.4590 - val_acc: 0.7755\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4670 - acc: 0.7713 - val_loss: 0.4521 - val_acc: 0.7782\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4611 - acc: 0.7748 - val_loss: 0.4499 - val_acc: 0.7788\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4560 - acc: 0.7781 - val_loss: 0.4395 - val_acc: 0.7881\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 67s 204us/step - loss: 0.4515 - acc: 0.7806 - val_loss: 0.4402 - val_acc: 0.7888\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 67s 206us/step - loss: 0.4470 - acc: 0.7842 - val_loss: 0.4397 - val_acc: 0.7884\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 66s 203us/step - loss: 0.4450 - acc: 0.7852 - val_loss: 0.4412 - val_acc: 0.7879\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4411 - acc: 0.7865 - val_loss: 0.4399 - val_acc: 0.7893\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 66s 201us/step - loss: 0.4388 - acc: 0.7891 - val_loss: 0.4361 - val_acc: 0.7893\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4365 - acc: 0.7906 - val_loss: 0.4329 - val_acc: 0.7917\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4349 - acc: 0.7906 - val_loss: 0.4333 - val_acc: 0.7933\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4335 - acc: 0.7920 - val_loss: 0.4317 - val_acc: 0.7942\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 67s 206us/step - loss: 0.4307 - acc: 0.7935 - val_loss: 0.4337 - val_acc: 0.7911\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 63s 194us/step - loss: 0.4294 - acc: 0.7949 - val_loss: 0.4332 - val_acc: 0.7938\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4270 - acc: 0.7962 - val_loss: 0.4268 - val_acc: 0.7951\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 64s 196us/step - loss: 0.4254 - acc: 0.7976 - val_loss: 0.4262 - val_acc: 0.7969\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4239 - acc: 0.7979 - val_loss: 0.4284 - val_acc: 0.7963\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 64s 196us/step - loss: 0.4222 - acc: 0.7995 - val_loss: 0.4241 - val_acc: 0.7973\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4212 - acc: 0.8001 - val_loss: 0.4265 - val_acc: 0.7971\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 64s 195us/step - loss: 0.4204 - acc: 0.7998 - val_loss: 0.4259 - val_acc: 0.7982\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 63s 192us/step - loss: 0.4189 - acc: 0.8003 - val_loss: 0.4281 - val_acc: 0.7972\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 63s 193us/step - loss: 0.4176 - acc: 0.8013 - val_loss: 0.4252 - val_acc: 0.7985\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4172 - acc: 0.8015 - val_loss: 0.4280 - val_acc: 0.7974\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 79s 240us/step - loss: 0.4157 - acc: 0.8027 - val_loss: 0.4227 - val_acc: 0.7988\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4151 - acc: 0.8036 - val_loss: 0.4237 - val_acc: 0.7995\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 66s 203us/step - loss: 0.4150 - acc: 0.8036 - val_loss: 0.4211 - val_acc: 0.8015\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 67s 205us/step - loss: 0.4139 - acc: 0.8045 - val_loss: 0.4225 - val_acc: 0.8007\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4125 - acc: 0.8050 - val_loss: 0.4226 - val_acc: 0.8017\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4121 - acc: 0.8047 - val_loss: 0.4231 - val_acc: 0.8001\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 68s 207us/step - loss: 0.4112 - acc: 0.8055 - val_loss: 0.4210 - val_acc: 0.8003\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.4104 - acc: 0.8065 - val_loss: 0.4237 - val_acc: 0.7988\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4093 - acc: 0.8068 - val_loss: 0.4279 - val_acc: 0.7965\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 66s 202us/step - loss: 0.4078 - acc: 0.8074 - val_loss: 0.4196 - val_acc: 0.8009\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4081 - acc: 0.8082 - val_loss: 0.4231 - val_acc: 0.8014\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4083 - acc: 0.8073 - val_loss: 0.4215 - val_acc: 0.8013\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 82s 249us/step - loss: 0.4066 - acc: 0.8088 - val_loss: 0.4185 - val_acc: 0.8018\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 87s 266us/step - loss: 0.4060 - acc: 0.8088 - val_loss: 0.4174 - val_acc: 0.8026\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 79s 242us/step - loss: 0.4046 - acc: 0.8097 - val_loss: 0.4207 - val_acc: 0.8009\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4047 - acc: 0.8090 - val_loss: 0.4182 - val_acc: 0.8020\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4037 - acc: 0.8104 - val_loss: 0.4256 - val_acc: 0.8006\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4038 - acc: 0.8101 - val_loss: 0.4250 - val_acc: 0.7979\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 71s 215us/step - loss: 0.4039 - acc: 0.8105 - val_loss: 0.4240 - val_acc: 0.8001\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4035 - acc: 0.8097 - val_loss: 0.4228 - val_acc: 0.8009\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 71s 215us/step - loss: 0.4035 - acc: 0.8104 - val_loss: 0.4229 - val_acc: 0.8027\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 68s 207us/step - loss: 0.4027 - acc: 0.8105 - val_loss: 0.4178 - val_acc: 0.8036\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4029 - acc: 0.8110 - val_loss: 0.4196 - val_acc: 0.8021\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4015 - acc: 0.8116 - val_loss: 0.4192 - val_acc: 0.8031\n",
      "Training ended at 2018-07-13 20:56:32.503877\n",
      "Minutes elapsed: 58.424754\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_5m\n",
      "Starting training at 2018-07-13 20:56:33.769356\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.5509 - acc: 0.7196 - val_loss: 0.5018 - val_acc: 0.7500\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.5081 - acc: 0.7474 - val_loss: 0.4774 - val_acc: 0.7616\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 72s 218us/step - loss: 0.4899 - acc: 0.7580 - val_loss: 0.4740 - val_acc: 0.7661\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4784 - acc: 0.7634 - val_loss: 0.4661 - val_acc: 0.7693\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4725 - acc: 0.7680 - val_loss: 0.4523 - val_acc: 0.7783\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4645 - acc: 0.7722 - val_loss: 0.4520 - val_acc: 0.7797\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4612 - acc: 0.7744 - val_loss: 0.4542 - val_acc: 0.7804\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4565 - acc: 0.7772 - val_loss: 0.4457 - val_acc: 0.7845\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4535 - acc: 0.7776 - val_loss: 0.4430 - val_acc: 0.7851\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4505 - acc: 0.7814 - val_loss: 0.4445 - val_acc: 0.7866\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4473 - acc: 0.7823 - val_loss: 0.4401 - val_acc: 0.7853\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4448 - acc: 0.7827 - val_loss: 0.4473 - val_acc: 0.7815\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.4421 - acc: 0.7854 - val_loss: 0.4433 - val_acc: 0.7816\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4399 - acc: 0.7883 - val_loss: 0.4372 - val_acc: 0.7891\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 65s 198us/step - loss: 0.4386 - acc: 0.7882 - val_loss: 0.4367 - val_acc: 0.7907\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 61s 187us/step - loss: 0.4360 - acc: 0.7899 - val_loss: 0.4408 - val_acc: 0.7870\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4359 - acc: 0.7897 - val_loss: 0.4349 - val_acc: 0.7896\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.4342 - acc: 0.7912 - val_loss: 0.4336 - val_acc: 0.7899\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4324 - acc: 0.7918 - val_loss: 0.4326 - val_acc: 0.7936\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4305 - acc: 0.7928 - val_loss: 0.4370 - val_acc: 0.7895\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4292 - acc: 0.7942 - val_loss: 0.4368 - val_acc: 0.7876\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4281 - acc: 0.7944 - val_loss: 0.4334 - val_acc: 0.7895\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4261 - acc: 0.7953 - val_loss: 0.4328 - val_acc: 0.7917\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.4253 - acc: 0.7957 - val_loss: 0.4324 - val_acc: 0.7914\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4242 - acc: 0.7962 - val_loss: 0.4277 - val_acc: 0.7946\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4232 - acc: 0.7974 - val_loss: 0.4317 - val_acc: 0.7938\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4216 - acc: 0.7982 - val_loss: 0.4272 - val_acc: 0.7962\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4204 - acc: 0.7993 - val_loss: 0.4326 - val_acc: 0.7932\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4210 - acc: 0.7991 - val_loss: 0.4301 - val_acc: 0.7940\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4202 - acc: 0.7994 - val_loss: 0.4283 - val_acc: 0.7940\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4185 - acc: 0.7997 - val_loss: 0.4266 - val_acc: 0.7950\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4175 - acc: 0.8011 - val_loss: 0.4271 - val_acc: 0.7951\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 67s 206us/step - loss: 0.4164 - acc: 0.8016 - val_loss: 0.4274 - val_acc: 0.7960\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4166 - acc: 0.8021 - val_loss: 0.4277 - val_acc: 0.7939\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4159 - acc: 0.8016 - val_loss: 0.4295 - val_acc: 0.7934\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4151 - acc: 0.8027 - val_loss: 0.4265 - val_acc: 0.7948\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4141 - acc: 0.8030 - val_loss: 0.4265 - val_acc: 0.7976\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4134 - acc: 0.8039 - val_loss: 0.4265 - val_acc: 0.7959\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4128 - acc: 0.8036 - val_loss: 0.4255 - val_acc: 0.7969\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4122 - acc: 0.8035 - val_loss: 0.4249 - val_acc: 0.7970\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4108 - acc: 0.8052 - val_loss: 0.4304 - val_acc: 0.7919\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4113 - acc: 0.8047 - val_loss: 0.4306 - val_acc: 0.7940\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4106 - acc: 0.8049 - val_loss: 0.4220 - val_acc: 0.7984\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4106 - acc: 0.8044 - val_loss: 0.4236 - val_acc: 0.7961\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4104 - acc: 0.8061 - val_loss: 0.4246 - val_acc: 0.7981\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4094 - acc: 0.8057 - val_loss: 0.4254 - val_acc: 0.7971\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4074 - acc: 0.8067 - val_loss: 0.4281 - val_acc: 0.7953\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4088 - acc: 0.8060 - val_loss: 0.4231 - val_acc: 0.7969\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4084 - acc: 0.8064 - val_loss: 0.4270 - val_acc: 0.7967\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4073 - acc: 0.8079 - val_loss: 0.4245 - val_acc: 0.7955\n",
      "Training ended at 2018-07-13 21:54:53.100863\n",
      "Minutes elapsed: 58.322190\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_4m\n",
      "Starting training at 2018-07-13 21:54:54.933664\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.5509 - acc: 0.7199 - val_loss: 0.4994 - val_acc: 0.7539\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.5036 - acc: 0.7509 - val_loss: 0.4874 - val_acc: 0.7601\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4877 - acc: 0.7587 - val_loss: 0.4708 - val_acc: 0.7699\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4773 - acc: 0.7656 - val_loss: 0.4613 - val_acc: 0.7722\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4697 - acc: 0.7707 - val_loss: 0.4546 - val_acc: 0.7759\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4627 - acc: 0.7746 - val_loss: 0.4498 - val_acc: 0.7807\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 72s 221us/step - loss: 0.4592 - acc: 0.7772 - val_loss: 0.4472 - val_acc: 0.7845\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4545 - acc: 0.7798 - val_loss: 0.4473 - val_acc: 0.7829\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4498 - acc: 0.7827 - val_loss: 0.4478 - val_acc: 0.7824\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4473 - acc: 0.7837 - val_loss: 0.4440 - val_acc: 0.7836\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4446 - acc: 0.7861 - val_loss: 0.4419 - val_acc: 0.7888\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4421 - acc: 0.7873 - val_loss: 0.4400 - val_acc: 0.7885\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4404 - acc: 0.7884 - val_loss: 0.4356 - val_acc: 0.7891\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.4390 - acc: 0.7893 - val_loss: 0.4380 - val_acc: 0.7890\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4362 - acc: 0.7907 - val_loss: 0.4326 - val_acc: 0.7906\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4344 - acc: 0.7923 - val_loss: 0.4339 - val_acc: 0.7921\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4331 - acc: 0.7931 - val_loss: 0.4355 - val_acc: 0.7920\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4310 - acc: 0.7944 - val_loss: 0.4331 - val_acc: 0.7927\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4302 - acc: 0.7948 - val_loss: 0.4314 - val_acc: 0.7946\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4290 - acc: 0.7953 - val_loss: 0.4328 - val_acc: 0.7917\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4276 - acc: 0.7960 - val_loss: 0.4319 - val_acc: 0.7920\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4263 - acc: 0.7963 - val_loss: 0.4304 - val_acc: 0.7940\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4255 - acc: 0.7972 - val_loss: 0.4265 - val_acc: 0.7954\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4234 - acc: 0.7993 - val_loss: 0.4287 - val_acc: 0.7955\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4236 - acc: 0.7992 - val_loss: 0.4269 - val_acc: 0.7974\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4220 - acc: 0.7994 - val_loss: 0.4271 - val_acc: 0.7948\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4205 - acc: 0.8000 - val_loss: 0.4273 - val_acc: 0.7957\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4201 - acc: 0.8004 - val_loss: 0.4314 - val_acc: 0.7967\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4191 - acc: 0.8010 - val_loss: 0.4297 - val_acc: 0.7964\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4189 - acc: 0.8013 - val_loss: 0.4247 - val_acc: 0.7985\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4169 - acc: 0.8024 - val_loss: 0.4270 - val_acc: 0.7965\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4164 - acc: 0.8025 - val_loss: 0.4237 - val_acc: 0.7957\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4162 - acc: 0.8030 - val_loss: 0.4279 - val_acc: 0.7976\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4153 - acc: 0.8037 - val_loss: 0.4260 - val_acc: 0.7974\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4149 - acc: 0.8032 - val_loss: 0.4243 - val_acc: 0.7974\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4145 - acc: 0.8041 - val_loss: 0.4252 - val_acc: 0.7981\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4145 - acc: 0.8045 - val_loss: 0.4226 - val_acc: 0.7996\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4125 - acc: 0.8056 - val_loss: 0.4246 - val_acc: 0.7994\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4125 - acc: 0.8048 - val_loss: 0.4238 - val_acc: 0.8001\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4115 - acc: 0.8062 - val_loss: 0.4213 - val_acc: 0.7997\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4109 - acc: 0.8067 - val_loss: 0.4256 - val_acc: 0.7979\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4103 - acc: 0.8066 - val_loss: 0.4252 - val_acc: 0.7986\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 72s 221us/step - loss: 0.4098 - acc: 0.8075 - val_loss: 0.4236 - val_acc: 0.7979\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.4097 - acc: 0.8068 - val_loss: 0.4215 - val_acc: 0.8008\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4099 - acc: 0.8074 - val_loss: 0.4208 - val_acc: 0.8012\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 71s 215us/step - loss: 0.4086 - acc: 0.8072 - val_loss: 0.4243 - val_acc: 0.7966\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4084 - acc: 0.8080 - val_loss: 0.4235 - val_acc: 0.7988\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4075 - acc: 0.8084 - val_loss: 0.4247 - val_acc: 0.8007\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 72s 221us/step - loss: 0.4064 - acc: 0.8090 - val_loss: 0.4213 - val_acc: 0.8025\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 72s 221us/step - loss: 0.4071 - acc: 0.8087 - val_loss: 0.4228 - val_acc: 0.8012\n",
      "Training ended at 2018-07-13 22:54:07.390001\n",
      "Minutes elapsed: 59.207604\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_3m\n",
      "Starting training at 2018-07-13 22:54:09.499390\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 76s 232us/step - loss: 0.5515 - acc: 0.7210 - val_loss: 0.5008 - val_acc: 0.7467\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 74s 226us/step - loss: 0.5042 - acc: 0.7503 - val_loss: 0.4858 - val_acc: 0.7591\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 74s 226us/step - loss: 0.4888 - acc: 0.7590 - val_loss: 0.4772 - val_acc: 0.7695\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 74s 225us/step - loss: 0.4784 - acc: 0.7641 - val_loss: 0.4624 - val_acc: 0.7741\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4701 - acc: 0.7696 - val_loss: 0.4552 - val_acc: 0.7781\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4643 - acc: 0.7730 - val_loss: 0.4567 - val_acc: 0.7784\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 76s 231us/step - loss: 0.4592 - acc: 0.7764 - val_loss: 0.4497 - val_acc: 0.7828\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4560 - acc: 0.7773 - val_loss: 0.4508 - val_acc: 0.7813\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 76s 234us/step - loss: 0.4528 - acc: 0.7797 - val_loss: 0.4525 - val_acc: 0.7827\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4500 - acc: 0.7823 - val_loss: 0.4435 - val_acc: 0.7833\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 76s 231us/step - loss: 0.4477 - acc: 0.7831 - val_loss: 0.4481 - val_acc: 0.7776\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4455 - acc: 0.7850 - val_loss: 0.4431 - val_acc: 0.7854\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.4427 - acc: 0.7864 - val_loss: 0.4440 - val_acc: 0.7837\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4411 - acc: 0.7867 - val_loss: 0.4413 - val_acc: 0.7856\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 74s 225us/step - loss: 0.4386 - acc: 0.7890 - val_loss: 0.4373 - val_acc: 0.7895\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4371 - acc: 0.7898 - val_loss: 0.4350 - val_acc: 0.7908\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4362 - acc: 0.7899 - val_loss: 0.4337 - val_acc: 0.7920\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4345 - acc: 0.7909 - val_loss: 0.4353 - val_acc: 0.7913\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 80s 243us/step - loss: 0.4325 - acc: 0.7923 - val_loss: 0.4376 - val_acc: 0.7906\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4315 - acc: 0.7935 - val_loss: 0.4334 - val_acc: 0.7938\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 74s 226us/step - loss: 0.4303 - acc: 0.7935 - val_loss: 0.4363 - val_acc: 0.7892\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 76s 232us/step - loss: 0.4284 - acc: 0.7956 - val_loss: 0.4327 - val_acc: 0.7953\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.4282 - acc: 0.7957 - val_loss: 0.4306 - val_acc: 0.7965\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4275 - acc: 0.7962 - val_loss: 0.4345 - val_acc: 0.7912\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4271 - acc: 0.7957 - val_loss: 0.4325 - val_acc: 0.7944\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 74s 226us/step - loss: 0.4243 - acc: 0.7982 - val_loss: 0.4310 - val_acc: 0.7942\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4239 - acc: 0.7982 - val_loss: 0.4322 - val_acc: 0.7938\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 76s 231us/step - loss: 0.4242 - acc: 0.7985 - val_loss: 0.4278 - val_acc: 0.7957\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4228 - acc: 0.7987 - val_loss: 0.4295 - val_acc: 0.7931\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4244 - acc: 0.7982 - val_loss: 0.4290 - val_acc: 0.7949\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4226 - acc: 0.7983 - val_loss: 0.4282 - val_acc: 0.7960\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4215 - acc: 0.7999 - val_loss: 0.4267 - val_acc: 0.7964\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4213 - acc: 0.7995 - val_loss: 0.4299 - val_acc: 0.7951\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4197 - acc: 0.8016 - val_loss: 0.4343 - val_acc: 0.7924\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 74s 225us/step - loss: 0.4193 - acc: 0.8006 - val_loss: 0.4278 - val_acc: 0.7973\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4182 - acc: 0.8006 - val_loss: 0.4254 - val_acc: 0.7978\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4177 - acc: 0.8017 - val_loss: 0.4319 - val_acc: 0.7945\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4196 - acc: 0.8008 - val_loss: 0.4274 - val_acc: 0.7960\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4172 - acc: 0.8023 - val_loss: 0.4256 - val_acc: 0.7964\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4168 - acc: 0.8027 - val_loss: 0.4325 - val_acc: 0.7920\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 75s 228us/step - loss: 0.4163 - acc: 0.8030 - val_loss: 0.4250 - val_acc: 0.7962\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4161 - acc: 0.8022 - val_loss: 0.4286 - val_acc: 0.7921\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 76s 234us/step - loss: 0.4160 - acc: 0.8020 - val_loss: 0.4269 - val_acc: 0.7972\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 81s 246us/step - loss: 0.4147 - acc: 0.8026 - val_loss: 0.4260 - val_acc: 0.7967\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 79s 241us/step - loss: 0.4142 - acc: 0.8042 - val_loss: 0.4264 - val_acc: 0.7960\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 77s 236us/step - loss: 0.4142 - acc: 0.8035 - val_loss: 0.4263 - val_acc: 0.7995\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4128 - acc: 0.8037 - val_loss: 0.4326 - val_acc: 0.7904\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4129 - acc: 0.8051 - val_loss: 0.4254 - val_acc: 0.7981\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4125 - acc: 0.8046 - val_loss: 0.4260 - val_acc: 0.7978\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 76s 232us/step - loss: 0.4138 - acc: 0.8042 - val_loss: 0.4263 - val_acc: 0.7993\n",
      "Training ended at 2018-07-13 23:57:20.463385\n",
      "Minutes elapsed: 63.182732\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_2m\n",
      "Starting training at 2018-07-13 23:57:22.938933\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 80s 244us/step - loss: 0.5534 - acc: 0.7189 - val_loss: 0.5038 - val_acc: 0.7520\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.5104 - acc: 0.7468 - val_loss: 0.4815 - val_acc: 0.7621\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4922 - acc: 0.7571 - val_loss: 0.4757 - val_acc: 0.7632\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4818 - acc: 0.7617 - val_loss: 0.4656 - val_acc: 0.7749\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4733 - acc: 0.7675 - val_loss: 0.4542 - val_acc: 0.7758\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4673 - acc: 0.7715 - val_loss: 0.4544 - val_acc: 0.7776\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4631 - acc: 0.7738 - val_loss: 0.4461 - val_acc: 0.7825\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4573 - acc: 0.7771 - val_loss: 0.4500 - val_acc: 0.7821\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 80s 244us/step - loss: 0.4551 - acc: 0.7786 - val_loss: 0.4435 - val_acc: 0.7829\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4517 - acc: 0.7814 - val_loss: 0.4436 - val_acc: 0.7852\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 79s 240us/step - loss: 0.4482 - acc: 0.7830 - val_loss: 0.4402 - val_acc: 0.7858\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 77s 237us/step - loss: 0.4466 - acc: 0.7833 - val_loss: 0.4403 - val_acc: 0.7865\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4435 - acc: 0.7858 - val_loss: 0.4458 - val_acc: 0.7827\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4414 - acc: 0.7868 - val_loss: 0.4403 - val_acc: 0.7885\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4412 - acc: 0.7868 - val_loss: 0.4392 - val_acc: 0.7868\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 79s 240us/step - loss: 0.4382 - acc: 0.7895 - val_loss: 0.4352 - val_acc: 0.7891\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 77s 236us/step - loss: 0.4366 - acc: 0.7896 - val_loss: 0.4364 - val_acc: 0.7890\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4351 - acc: 0.7906 - val_loss: 0.4311 - val_acc: 0.7921\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4333 - acc: 0.7917 - val_loss: 0.4355 - val_acc: 0.7868\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 79s 240us/step - loss: 0.4324 - acc: 0.7925 - val_loss: 0.4307 - val_acc: 0.7929\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.4304 - acc: 0.7935 - val_loss: 0.4310 - val_acc: 0.7944\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 79s 241us/step - loss: 0.4296 - acc: 0.7940 - val_loss: 0.4325 - val_acc: 0.7909\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 79s 242us/step - loss: 0.4279 - acc: 0.7951 - val_loss: 0.4289 - val_acc: 0.7941\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4264 - acc: 0.7960 - val_loss: 0.4279 - val_acc: 0.7948\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4253 - acc: 0.7975 - val_loss: 0.4293 - val_acc: 0.7953\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4249 - acc: 0.7977 - val_loss: 0.4289 - val_acc: 0.7943\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 79s 242us/step - loss: 0.4250 - acc: 0.7972 - val_loss: 0.4291 - val_acc: 0.7937\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 76s 231us/step - loss: 0.4232 - acc: 0.7977 - val_loss: 0.4308 - val_acc: 0.7937\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.4220 - acc: 0.7989 - val_loss: 0.4271 - val_acc: 0.7972\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 81s 247us/step - loss: 0.4212 - acc: 0.7995 - val_loss: 0.4299 - val_acc: 0.7920\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.4201 - acc: 0.8001 - val_loss: 0.4314 - val_acc: 0.7935\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 77s 235us/step - loss: 0.4195 - acc: 0.8005 - val_loss: 0.4299 - val_acc: 0.7945\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 80s 243us/step - loss: 0.4189 - acc: 0.8002 - val_loss: 0.4297 - val_acc: 0.7946\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 78s 239us/step - loss: 0.4180 - acc: 0.8010 - val_loss: 0.4302 - val_acc: 0.7948\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 80s 245us/step - loss: 0.4175 - acc: 0.8019 - val_loss: 0.4254 - val_acc: 0.7959\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4166 - acc: 0.8015 - val_loss: 0.4267 - val_acc: 0.7956\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4155 - acc: 0.8026 - val_loss: 0.4254 - val_acc: 0.7981\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4152 - acc: 0.8026 - val_loss: 0.4294 - val_acc: 0.7965\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4151 - acc: 0.8025 - val_loss: 0.4266 - val_acc: 0.7970\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 81s 247us/step - loss: 0.4134 - acc: 0.8042 - val_loss: 0.4248 - val_acc: 0.7980\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 80s 244us/step - loss: 0.4139 - acc: 0.8037 - val_loss: 0.4260 - val_acc: 0.7985\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 80s 245us/step - loss: 0.4124 - acc: 0.8048 - val_loss: 0.4254 - val_acc: 0.7965\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 79s 243us/step - loss: 0.4117 - acc: 0.8046 - val_loss: 0.4252 - val_acc: 0.7981\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 81s 248us/step - loss: 0.4111 - acc: 0.8055 - val_loss: 0.4249 - val_acc: 0.7973\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4106 - acc: 0.8052 - val_loss: 0.4239 - val_acc: 0.7989\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.4106 - acc: 0.8051 - val_loss: 0.4283 - val_acc: 0.7980\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4089 - acc: 0.8067 - val_loss: 0.4244 - val_acc: 0.7985\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 80s 244us/step - loss: 0.4085 - acc: 0.8060 - val_loss: 0.4262 - val_acc: 0.7992\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 82s 251us/step - loss: 0.4080 - acc: 0.8072 - val_loss: 0.4245 - val_acc: 0.7997\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 78s 238us/step - loss: 0.4083 - acc: 0.8075 - val_loss: 0.4267 - val_acc: 0.7980\n",
      "Training ended at 2018-07-14 01:03:19.501328\n",
      "Minutes elapsed: 65.942706\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_1m\n",
      "Starting training at 2018-07-14 01:03:22.345535\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 85s 260us/step - loss: 0.5543 - acc: 0.7172 - val_loss: 0.5078 - val_acc: 0.7489\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.5113 - acc: 0.7442 - val_loss: 0.4889 - val_acc: 0.7546\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4967 - acc: 0.7537 - val_loss: 0.4780 - val_acc: 0.7655\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 84s 258us/step - loss: 0.4861 - acc: 0.7596 - val_loss: 0.4756 - val_acc: 0.7680\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 84s 257us/step - loss: 0.4781 - acc: 0.7636 - val_loss: 0.4709 - val_acc: 0.7681\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4725 - acc: 0.7662 - val_loss: 0.4654 - val_acc: 0.7737\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 82s 251us/step - loss: 0.4681 - acc: 0.7695 - val_loss: 0.4751 - val_acc: 0.7673\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4654 - acc: 0.7711 - val_loss: 0.4589 - val_acc: 0.7743\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 84s 257us/step - loss: 0.4621 - acc: 0.7728 - val_loss: 0.4587 - val_acc: 0.7738\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4581 - acc: 0.7763 - val_loss: 0.4567 - val_acc: 0.7760\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4561 - acc: 0.7764 - val_loss: 0.4530 - val_acc: 0.7793\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 82s 251us/step - loss: 0.4534 - acc: 0.7786 - val_loss: 0.4493 - val_acc: 0.7815\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4511 - acc: 0.7806 - val_loss: 0.4527 - val_acc: 0.7817\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 82s 249us/step - loss: 0.4495 - acc: 0.7809 - val_loss: 0.4512 - val_acc: 0.7796\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4490 - acc: 0.7814 - val_loss: 0.4509 - val_acc: 0.7828\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 82s 252us/step - loss: 0.4472 - acc: 0.7830 - val_loss: 0.4470 - val_acc: 0.7842\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 85s 260us/step - loss: 0.4459 - acc: 0.7834 - val_loss: 0.4466 - val_acc: 0.7836\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 85s 260us/step - loss: 0.4429 - acc: 0.7852 - val_loss: 0.4454 - val_acc: 0.7851\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 86s 262us/step - loss: 0.4412 - acc: 0.7866 - val_loss: 0.4435 - val_acc: 0.7849\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 83s 255us/step - loss: 0.4398 - acc: 0.7870 - val_loss: 0.4425 - val_acc: 0.7857\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 86s 261us/step - loss: 0.4390 - acc: 0.7878 - val_loss: 0.4451 - val_acc: 0.7861\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4371 - acc: 0.7891 - val_loss: 0.4432 - val_acc: 0.7841\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 82s 252us/step - loss: 0.4369 - acc: 0.7890 - val_loss: 0.4451 - val_acc: 0.7850\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4360 - acc: 0.7899 - val_loss: 0.4454 - val_acc: 0.7815\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4346 - acc: 0.7904 - val_loss: 0.4435 - val_acc: 0.7846\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 84s 258us/step - loss: 0.4331 - acc: 0.7919 - val_loss: 0.4447 - val_acc: 0.7862\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4337 - acc: 0.7915 - val_loss: 0.4405 - val_acc: 0.7871\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 83s 254us/step - loss: 0.4322 - acc: 0.7922 - val_loss: 0.4429 - val_acc: 0.7884\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 82s 251us/step - loss: 0.4311 - acc: 0.7925 - val_loss: 0.4418 - val_acc: 0.7890\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4316 - acc: 0.7925 - val_loss: 0.4400 - val_acc: 0.7890\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 85s 259us/step - loss: 0.4300 - acc: 0.7935 - val_loss: 0.4415 - val_acc: 0.7873\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4296 - acc: 0.7934 - val_loss: 0.4417 - val_acc: 0.7865\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 82s 250us/step - loss: 0.4286 - acc: 0.7941 - val_loss: 0.4391 - val_acc: 0.7879\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4293 - acc: 0.7935 - val_loss: 0.4424 - val_acc: 0.7833\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4273 - acc: 0.7948 - val_loss: 0.4387 - val_acc: 0.7887\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4273 - acc: 0.7947 - val_loss: 0.4374 - val_acc: 0.7895\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 83s 253us/step - loss: 0.4263 - acc: 0.7954 - val_loss: 0.4378 - val_acc: 0.7874\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 84s 255us/step - loss: 0.4257 - acc: 0.7963 - val_loss: 0.4381 - val_acc: 0.7898\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 83s 252us/step - loss: 0.4234 - acc: 0.7964 - val_loss: 0.4404 - val_acc: 0.7891\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.4240 - acc: 0.7964 - val_loss: 0.4384 - val_acc: 0.7876\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4238 - acc: 0.7961 - val_loss: 0.4394 - val_acc: 0.7877\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4230 - acc: 0.7972 - val_loss: 0.4371 - val_acc: 0.7886\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.4211 - acc: 0.7982 - val_loss: 0.4349 - val_acc: 0.7915\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 76s 233us/step - loss: 0.4215 - acc: 0.7979 - val_loss: 0.4357 - val_acc: 0.7884\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 80s 244us/step - loss: 0.4208 - acc: 0.7979 - val_loss: 0.4368 - val_acc: 0.7875\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 83s 255us/step - loss: 0.4202 - acc: 0.7990 - val_loss: 0.4340 - val_acc: 0.7899\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.4197 - acc: 0.7992 - val_loss: 0.4363 - val_acc: 0.7862\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4195 - acc: 0.7995 - val_loss: 0.4347 - val_acc: 0.7902\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 84s 257us/step - loss: 0.4192 - acc: 0.7998 - val_loss: 0.4361 - val_acc: 0.7894\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4187 - acc: 0.7998 - val_loss: 0.4336 - val_acc: 0.7887\n",
      "Training ended at 2018-07-14 02:11:47.753649\n",
      "Minutes elapsed: 68.423468\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_05m\n",
      "Starting training at 2018-07-14 02:11:51.205516\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 91s 276us/step - loss: 0.5579 - acc: 0.7159 - val_loss: 0.5114 - val_acc: 0.7447\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.5155 - acc: 0.7431 - val_loss: 0.4951 - val_acc: 0.7546\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.5007 - acc: 0.7513 - val_loss: 0.4821 - val_acc: 0.7643\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 72s 220us/step - loss: 0.4903 - acc: 0.7575 - val_loss: 0.4787 - val_acc: 0.7660\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.4823 - acc: 0.7626 - val_loss: 0.4765 - val_acc: 0.7682\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.4770 - acc: 0.7659 - val_loss: 0.4717 - val_acc: 0.7697\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4713 - acc: 0.7690 - val_loss: 0.4659 - val_acc: 0.7713\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 74s 227us/step - loss: 0.4681 - acc: 0.7711 - val_loss: 0.4628 - val_acc: 0.7730\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 96s 293us/step - loss: 0.4649 - acc: 0.7732 - val_loss: 0.4608 - val_acc: 0.7772\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 79s 242us/step - loss: 0.4617 - acc: 0.7751 - val_loss: 0.4626 - val_acc: 0.7739\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 78s 237us/step - loss: 0.4587 - acc: 0.7765 - val_loss: 0.4572 - val_acc: 0.7772\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 79s 243us/step - loss: 0.4565 - acc: 0.7779 - val_loss: 0.4617 - val_acc: 0.7747\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4540 - acc: 0.7795 - val_loss: 0.4525 - val_acc: 0.7815\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4525 - acc: 0.7802 - val_loss: 0.4484 - val_acc: 0.7840\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4512 - acc: 0.7810 - val_loss: 0.4534 - val_acc: 0.7805\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 80s 245us/step - loss: 0.4493 - acc: 0.7826 - val_loss: 0.4507 - val_acc: 0.7821\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 84s 256us/step - loss: 0.4478 - acc: 0.7827 - val_loss: 0.4476 - val_acc: 0.7845\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 82s 249us/step - loss: 0.4460 - acc: 0.7844 - val_loss: 0.4501 - val_acc: 0.7824\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 80s 243us/step - loss: 0.4445 - acc: 0.7851 - val_loss: 0.4465 - val_acc: 0.7835\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 79s 242us/step - loss: 0.4435 - acc: 0.7864 - val_loss: 0.4487 - val_acc: 0.7844\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4433 - acc: 0.7863 - val_loss: 0.4473 - val_acc: 0.7853\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 74s 226us/step - loss: 0.4401 - acc: 0.7879 - val_loss: 0.4530 - val_acc: 0.7800\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4394 - acc: 0.7889 - val_loss: 0.4469 - val_acc: 0.7847\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 77s 234us/step - loss: 0.4387 - acc: 0.7891 - val_loss: 0.4454 - val_acc: 0.7846\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 75s 230us/step - loss: 0.4374 - acc: 0.7895 - val_loss: 0.4444 - val_acc: 0.7844\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4359 - acc: 0.7912 - val_loss: 0.4434 - val_acc: 0.7874\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 73s 224us/step - loss: 0.4360 - acc: 0.7915 - val_loss: 0.4458 - val_acc: 0.7862\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 75s 229us/step - loss: 0.4343 - acc: 0.7918 - val_loss: 0.4431 - val_acc: 0.7851\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4332 - acc: 0.7925 - val_loss: 0.4430 - val_acc: 0.7855\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.4330 - acc: 0.7931 - val_loss: 0.4417 - val_acc: 0.7879\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4317 - acc: 0.7931 - val_loss: 0.4448 - val_acc: 0.7844\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 72s 219us/step - loss: 0.4303 - acc: 0.7946 - val_loss: 0.4464 - val_acc: 0.7838\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4302 - acc: 0.7938 - val_loss: 0.4411 - val_acc: 0.7866\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4301 - acc: 0.7935 - val_loss: 0.4399 - val_acc: 0.7884\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4285 - acc: 0.7949 - val_loss: 0.4393 - val_acc: 0.7887\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 68s 208us/step - loss: 0.4283 - acc: 0.7962 - val_loss: 0.4437 - val_acc: 0.7868\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 69s 209us/step - loss: 0.4277 - acc: 0.7952 - val_loss: 0.4466 - val_acc: 0.7835\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4264 - acc: 0.7966 - val_loss: 0.4425 - val_acc: 0.7848\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4254 - acc: 0.7966 - val_loss: 0.4397 - val_acc: 0.7883\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4257 - acc: 0.7967 - val_loss: 0.4381 - val_acc: 0.7893\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4258 - acc: 0.7966 - val_loss: 0.4403 - val_acc: 0.7882\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4255 - acc: 0.7964 - val_loss: 0.4428 - val_acc: 0.7866\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 68s 209us/step - loss: 0.4239 - acc: 0.7983 - val_loss: 0.4404 - val_acc: 0.7875\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4246 - acc: 0.7976 - val_loss: 0.4398 - val_acc: 0.7881\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 69s 209us/step - loss: 0.4230 - acc: 0.7982 - val_loss: 0.4394 - val_acc: 0.7889\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 69s 209us/step - loss: 0.4232 - acc: 0.7984 - val_loss: 0.4394 - val_acc: 0.7870\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4221 - acc: 0.7989 - val_loss: 0.4383 - val_acc: 0.7887\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 69s 210us/step - loss: 0.4219 - acc: 0.7987 - val_loss: 0.4395 - val_acc: 0.7884\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4226 - acc: 0.7986 - val_loss: 0.4415 - val_acc: 0.7860\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 69s 209us/step - loss: 0.4221 - acc: 0.7996 - val_loss: 0.4360 - val_acc: 0.7906\n",
      "Training ended at 2018-07-14 03:13:11.754088\n",
      "Minutes elapsed: 61.342475\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_01m\n",
      "Starting training at 2018-07-14 03:13:15.105802\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 71s 218us/step - loss: 0.5654 - acc: 0.7099 - val_loss: 0.5195 - val_acc: 0.7403\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.5241 - acc: 0.7375 - val_loss: 0.5295 - val_acc: 0.7358\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.5085 - acc: 0.7457 - val_loss: 0.5205 - val_acc: 0.7370\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4991 - acc: 0.7512 - val_loss: 0.4967 - val_acc: 0.7504\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4931 - acc: 0.7553 - val_loss: 0.4805 - val_acc: 0.7641\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4878 - acc: 0.7588 - val_loss: 0.4812 - val_acc: 0.7613\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4828 - acc: 0.7619 - val_loss: 0.4723 - val_acc: 0.7696\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4794 - acc: 0.7646 - val_loss: 0.4787 - val_acc: 0.7602\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4760 - acc: 0.7666 - val_loss: 0.4714 - val_acc: 0.7704\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4734 - acc: 0.7687 - val_loss: 0.4759 - val_acc: 0.7694\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4694 - acc: 0.7699 - val_loss: 0.4665 - val_acc: 0.7714\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4679 - acc: 0.7716 - val_loss: 0.4697 - val_acc: 0.7710\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4657 - acc: 0.7736 - val_loss: 0.4627 - val_acc: 0.7769\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4635 - acc: 0.7738 - val_loss: 0.4648 - val_acc: 0.7731\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4625 - acc: 0.7752 - val_loss: 0.4636 - val_acc: 0.7748\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4608 - acc: 0.7760 - val_loss: 0.4584 - val_acc: 0.7782\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4586 - acc: 0.7766 - val_loss: 0.4584 - val_acc: 0.7776\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4576 - acc: 0.7782 - val_loss: 0.4612 - val_acc: 0.7749\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4547 - acc: 0.7793 - val_loss: 0.4604 - val_acc: 0.7775\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4541 - acc: 0.7792 - val_loss: 0.4731 - val_acc: 0.7663\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4535 - acc: 0.7807 - val_loss: 0.4561 - val_acc: 0.7784\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4519 - acc: 0.7816 - val_loss: 0.4557 - val_acc: 0.7777\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4497 - acc: 0.7828 - val_loss: 0.4548 - val_acc: 0.7774\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4484 - acc: 0.7837 - val_loss: 0.4537 - val_acc: 0.7811\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4476 - acc: 0.7832 - val_loss: 0.4540 - val_acc: 0.7790\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4466 - acc: 0.7842 - val_loss: 0.4518 - val_acc: 0.7799\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4455 - acc: 0.7847 - val_loss: 0.4544 - val_acc: 0.7791\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4450 - acc: 0.7860 - val_loss: 0.4504 - val_acc: 0.7812\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4446 - acc: 0.7850 - val_loss: 0.4531 - val_acc: 0.7811\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4421 - acc: 0.7868 - val_loss: 0.4496 - val_acc: 0.7834\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4417 - acc: 0.7872 - val_loss: 0.4527 - val_acc: 0.7821\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4414 - acc: 0.7875 - val_loss: 0.4500 - val_acc: 0.7823\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4419 - acc: 0.7864 - val_loss: 0.4550 - val_acc: 0.7783\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4408 - acc: 0.7878 - val_loss: 0.4532 - val_acc: 0.7803\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4398 - acc: 0.7879 - val_loss: 0.4518 - val_acc: 0.7811\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4381 - acc: 0.7891 - val_loss: 0.4489 - val_acc: 0.7823\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4377 - acc: 0.7895 - val_loss: 0.4496 - val_acc: 0.7830\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4361 - acc: 0.7902 - val_loss: 0.4526 - val_acc: 0.7785\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4356 - acc: 0.7907 - val_loss: 0.4477 - val_acc: 0.7819\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4373 - acc: 0.7899 - val_loss: 0.4545 - val_acc: 0.7790\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4346 - acc: 0.7914 - val_loss: 0.4495 - val_acc: 0.7824\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4338 - acc: 0.7922 - val_loss: 0.4464 - val_acc: 0.7846\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4342 - acc: 0.7914 - val_loss: 0.4472 - val_acc: 0.7849\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4324 - acc: 0.7923 - val_loss: 0.4503 - val_acc: 0.7823\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4317 - acc: 0.7924 - val_loss: 0.4490 - val_acc: 0.7854\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4316 - acc: 0.7932 - val_loss: 0.4455 - val_acc: 0.7840\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 70s 213us/step - loss: 0.4316 - acc: 0.7927 - val_loss: 0.4446 - val_acc: 0.7849\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 70s 212us/step - loss: 0.4322 - acc: 0.7926 - val_loss: 0.4480 - val_acc: 0.7842\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 69s 211us/step - loss: 0.4313 - acc: 0.7926 - val_loss: 0.4500 - val_acc: 0.7821\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 69s 212us/step - loss: 0.4303 - acc: 0.7940 - val_loss: 0.4448 - val_acc: 0.7856\n",
      "Training ended at 2018-07-14 04:11:16.515515\n",
      "Minutes elapsed: 58.023494\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_005m\n",
      "Starting training at 2018-07-14 04:11:20.119228\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5733 - acc: 0.7057 - val_loss: 0.5450 - val_acc: 0.7220\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.5345 - acc: 0.7317 - val_loss: 0.5142 - val_acc: 0.7433\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.5194 - acc: 0.7413 - val_loss: 0.5034 - val_acc: 0.7512\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 71s 215us/step - loss: 0.5102 - acc: 0.7463 - val_loss: 0.4987 - val_acc: 0.7529\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.5017 - acc: 0.7518 - val_loss: 0.4950 - val_acc: 0.7561\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4952 - acc: 0.7557 - val_loss: 0.4845 - val_acc: 0.7594\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4913 - acc: 0.7575 - val_loss: 0.4976 - val_acc: 0.7506\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4864 - acc: 0.7607 - val_loss: 0.4850 - val_acc: 0.7583\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4834 - acc: 0.7626 - val_loss: 0.4820 - val_acc: 0.7622\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4801 - acc: 0.7645 - val_loss: 0.4878 - val_acc: 0.7599\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4778 - acc: 0.7655 - val_loss: 0.4788 - val_acc: 0.7646\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4762 - acc: 0.7670 - val_loss: 0.4714 - val_acc: 0.7692\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4728 - acc: 0.7691 - val_loss: 0.4756 - val_acc: 0.7642\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4713 - acc: 0.7694 - val_loss: 0.4791 - val_acc: 0.7630\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4693 - acc: 0.7703 - val_loss: 0.4692 - val_acc: 0.7735\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4682 - acc: 0.7715 - val_loss: 0.4722 - val_acc: 0.7698\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4665 - acc: 0.7727 - val_loss: 0.4631 - val_acc: 0.7724\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4651 - acc: 0.7732 - val_loss: 0.4694 - val_acc: 0.7697\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4638 - acc: 0.7741 - val_loss: 0.4693 - val_acc: 0.7694\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4626 - acc: 0.7751 - val_loss: 0.4642 - val_acc: 0.7736\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4614 - acc: 0.7757 - val_loss: 0.4705 - val_acc: 0.7685\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4592 - acc: 0.7768 - val_loss: 0.4629 - val_acc: 0.7748\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4583 - acc: 0.7775 - val_loss: 0.4902 - val_acc: 0.7549\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4582 - acc: 0.7769 - val_loss: 0.4587 - val_acc: 0.7770\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4573 - acc: 0.7781 - val_loss: 0.4665 - val_acc: 0.7750\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4551 - acc: 0.7791 - val_loss: 0.4568 - val_acc: 0.7788\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4541 - acc: 0.7806 - val_loss: 0.4585 - val_acc: 0.7776\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4533 - acc: 0.7805 - val_loss: 0.4627 - val_acc: 0.7740\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4531 - acc: 0.7804 - val_loss: 0.4637 - val_acc: 0.7747\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4511 - acc: 0.7822 - val_loss: 0.4618 - val_acc: 0.7764\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4499 - acc: 0.7826 - val_loss: 0.4569 - val_acc: 0.7769\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4503 - acc: 0.7820 - val_loss: 0.4585 - val_acc: 0.7804\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4487 - acc: 0.7836 - val_loss: 0.4560 - val_acc: 0.7777\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4483 - acc: 0.7833 - val_loss: 0.4583 - val_acc: 0.7768\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4477 - acc: 0.7840 - val_loss: 0.4522 - val_acc: 0.7821\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4455 - acc: 0.7847 - val_loss: 0.4555 - val_acc: 0.7782\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4468 - acc: 0.7846 - val_loss: 0.4542 - val_acc: 0.7816\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4456 - acc: 0.7852 - val_loss: 0.4535 - val_acc: 0.7806\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4441 - acc: 0.7861 - val_loss: 0.4524 - val_acc: 0.7830\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4443 - acc: 0.7851 - val_loss: 0.4705 - val_acc: 0.7665\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4424 - acc: 0.7868 - val_loss: 0.4515 - val_acc: 0.7804\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4422 - acc: 0.7881 - val_loss: 0.4509 - val_acc: 0.7834\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4409 - acc: 0.7880 - val_loss: 0.4529 - val_acc: 0.7797\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 70s 215us/step - loss: 0.4408 - acc: 0.7872 - val_loss: 0.4513 - val_acc: 0.7819\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 71s 216us/step - loss: 0.4415 - acc: 0.7870 - val_loss: 0.4537 - val_acc: 0.7792\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4414 - acc: 0.7873 - val_loss: 0.4547 - val_acc: 0.7794\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 71s 217us/step - loss: 0.4407 - acc: 0.7877 - val_loss: 0.4532 - val_acc: 0.7808\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4398 - acc: 0.7883 - val_loss: 0.4547 - val_acc: 0.7806\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4382 - acc: 0.7891 - val_loss: 0.4530 - val_acc: 0.7821\n",
      "Epoch 50/50\n",
      "327472/327472 [==============================] - 70s 214us/step - loss: 0.4389 - acc: 0.7889 - val_loss: 0.4555 - val_acc: 0.7829\n",
      "Training ended at 2018-07-14 05:10:02.774966\n",
      "Minutes elapsed: 58.710928\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "current embedding:  pivots300_001m\n",
      "Starting training at 2018-07-14 05:10:07.086063\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/50\n",
      "327472/327472 [==============================] - 74s 225us/step - loss: 0.6007 - acc: 0.6704 - val_loss: 6.0511 - val_acc: 0.3645\n",
      "Epoch 2/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5780 - acc: 0.6954 - val_loss: 0.8716 - val_acc: 0.6369\n",
      "Epoch 3/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5766 - acc: 0.6979 - val_loss: 0.6802 - val_acc: 0.6448\n",
      "Epoch 4/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.5767 - acc: 0.6974 - val_loss: 1.6012 - val_acc: 0.3761\n",
      "Epoch 5/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5752 - acc: 0.6994 - val_loss: 0.6663 - val_acc: 0.5676\n",
      "Epoch 6/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5754 - acc: 0.6988 - val_loss: 0.8389 - val_acc: 0.6355\n",
      "Epoch 7/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5744 - acc: 0.7003 - val_loss: 0.8795 - val_acc: 0.6355\n",
      "Epoch 8/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.5723 - acc: 0.6992 - val_loss: 0.5928 - val_acc: 0.6691\n",
      "Epoch 9/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5694 - acc: 0.7017 - val_loss: 0.8710 - val_acc: 0.6355\n",
      "Epoch 10/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5729 - acc: 0.7012 - val_loss: 0.7049 - val_acc: 0.6384\n",
      "Epoch 11/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5708 - acc: 0.7018 - val_loss: 0.7739 - val_acc: 0.5666\n",
      "Epoch 12/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.5657 - acc: 0.7056 - val_loss: 1.1504 - val_acc: 0.4497\n",
      "Epoch 13/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5654 - acc: 0.7059 - val_loss: 0.5943 - val_acc: 0.6762\n",
      "Epoch 14/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5646 - acc: 0.7075 - val_loss: 0.7014 - val_acc: 0.5782\n",
      "Epoch 15/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5660 - acc: 0.7059 - val_loss: 0.5801 - val_acc: 0.6872\n",
      "Epoch 16/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.5866 - acc: 0.6892 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 17/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6591 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 18/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 19/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6589 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 20/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6571 - val_acc: 0.6355\n",
      "Epoch 21/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 22/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 23/50\n",
      "327472/327472 [==============================] - 73s 221us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 24/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6568 - val_acc: 0.6355\n",
      "Epoch 25/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 26/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 27/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 28/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 29/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 30/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 31/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6565 - val_acc: 0.6355\n",
      "Epoch 32/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 33/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6563 - val_acc: 0.6355\n",
      "Epoch 34/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 35/50\n",
      "327472/327472 [==============================] - 73s 221us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 36/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6562 - val_acc: 0.6355\n",
      "Epoch 37/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6563 - val_acc: 0.6355\n",
      "Epoch 38/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6562 - val_acc: 0.6355\n",
      "Epoch 39/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 40/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 41/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 42/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6574 - val_acc: 0.6355\n",
      "Epoch 43/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 44/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6589 - acc: 0.6303 - val_loss: 0.6564 - val_acc: 0.6355\n",
      "Epoch 45/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 46/50\n",
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 47/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6563 - val_acc: 0.6355\n",
      "Epoch 48/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Epoch 49/50\n",
      "327472/327472 [==============================] - 73s 223us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6561 - val_acc: 0.6355\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327472/327472 [==============================] - 73s 222us/step - loss: 0.6590 - acc: 0.6303 - val_loss: 0.6560 - val_acc: 0.6355\n",
      "Training ended at 2018-07-14 06:10:50.125781\n",
      "Minutes elapsed: 60.717328\n",
      "-------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "save_data = {}\n",
    "for embed_name in w2v_embedding.keys():\n",
    "    current_embed = w2v_embedding[embed_name]\n",
    "    model = Max_BoE(current_embed)\n",
    "    MODEL_WEIGHTS_FILE = '/Users/zhang/MscProject_tweak2vec/Max_BOE_weights/'+embed_name+'_weights.h5'\n",
    "    print('current embedding: ',embed_name)\n",
    "    print(\"Starting training at\", datetime.datetime.now())\n",
    "    t0 = time.time()\n",
    "    callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "    model_history = model.fit([Q1_train, Q2_train],\n",
    "                        y_train,\n",
    "                        epochs=n_epoch,\n",
    "                        validation_split=val_split,\n",
    "                        verbose=1,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=callbacks)\n",
    "    save_data[embed_name] = model_history.history\n",
    "    t1 = time.time()\n",
    "    print(\"Training ended at\", datetime.datetime.now())\n",
    "    print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))\n",
    "    print(\"-------------------------------------------------------------------------\") \n",
    "    print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('pivots300_data.txt','w')\n",
    "f.write(str(save_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4726, accuracy = 0.8038\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 25, 50)       1515000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 25, 50)       1515000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 25, 50)       2550        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 25, 50)       2550        embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 50)           0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 50)           0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100)          0           lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 200)          20200       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 200)          800         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 200)          40200       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 200)          800         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 200)          40200       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 200)          800         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 200)          40200       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 200)          0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200)          800         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            201         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,179,301\n",
      "Trainable params: 147,701\n",
      "Non-trainable params: 3,031,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
